{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame - Operations\n",
    "Now that you know the basics, let's get into operations. \n",
    "\n",
    "Objective: This exercise is similar to the Basics exercise, but uses DataFrame methods instead of SQL. We'll also be going through some more complex operations with a more realisitic dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/04 05:13:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/04 05:13:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/05/04 05:13:50 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/05/04 05:13:50 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('operations').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schemas can only be inferred for CSV files. \n",
    "df = spark.read.csv('Datasets/apple_stock_data.csv', inferSchema=True, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's get a better look at the data.\n",
    "# We know that we can show a DataFrame, but that's resulted in a mess! \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2010-01-04', Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039),\n",
       " Row(Date='2010-01-05', Open=214.599998, High=215.589994, Low=213.249994, Close=214.379993, Volume=150476200, Adj Close=27.774976000000002),\n",
       " Row(Date='2010-01-06', Open=214.379993, High=215.23, Low=210.750004, Close=210.969995, Volume=138040000, Adj Close=27.333178000000004),\n",
       " Row(Date='2010-01-07', Open=211.75, High=212.000006, Low=209.050005, Close=210.58, Volume=119282800, Adj Close=27.28265),\n",
       " Row(Date='2010-01-08', Open=210.299994, High=212.000006, Low=209.06000500000002, Close=211.98000499999998, Volume=111902700, Adj Close=27.464034)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, let's just grab the first row. Much neater! \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+\n",
      "|      Date|              Open|             Close|\n",
      "+----------+------------------+------------------+\n",
      "|2010-01-22|206.78000600000001|            197.75|\n",
      "|2010-01-28|        204.930004|        199.289995|\n",
      "|2010-01-29|        201.079996|        192.060003|\n",
      "|2010-02-01|192.36999699999998|        194.729998|\n",
      "|2010-02-02|        195.909998|        195.859997|\n",
      "|2010-02-03|        195.169994|        199.229994|\n",
      "|2010-02-04|        196.730003|        192.050003|\n",
      "|2010-02-05|192.63000300000002|        195.460001|\n",
      "|2010-02-08|        195.690006|194.11999699999998|\n",
      "|2010-02-09|        196.419996|196.19000400000002|\n",
      "|2010-02-10|        195.889997|195.12000700000002|\n",
      "|2010-02-11|        194.880001|        198.669994|\n",
      "|2010-02-23|        199.999998|        197.059998|\n",
      "|2014-06-09|         92.699997|         93.699997|\n",
      "|2014-06-10|         94.730003|             94.25|\n",
      "|2014-06-11|         94.129997|         93.860001|\n",
      "|2014-06-12|         94.040001|         92.290001|\n",
      "|2014-06-13|         92.199997|         91.279999|\n",
      "|2014-06-16|         91.510002|         92.199997|\n",
      "|2014-06-17|         92.309998| 92.08000200000001|\n",
      "+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+------------------+------------------+\n",
      "|      Date|              Open|             Close|\n",
      "+----------+------------------+------------------+\n",
      "|2010-02-01|192.36999699999998|        194.729998|\n",
      "|2010-02-02|        195.909998|        195.859997|\n",
      "|2010-02-03|        195.169994|        199.229994|\n",
      "|2010-02-04|        196.730003|        192.050003|\n",
      "|2010-02-05|192.63000300000002|        195.460001|\n",
      "|2010-02-08|        195.690006|194.11999699999998|\n",
      "|2010-02-09|        196.419996|196.19000400000002|\n",
      "|2010-02-10|        195.889997|195.12000700000002|\n",
      "|2010-02-11|        194.880001|        198.669994|\n",
      "|2010-02-23|        199.999998|        197.059998|\n",
      "|2014-06-09|         92.699997|         93.699997|\n",
      "|2014-06-10|         94.730003|             94.25|\n",
      "|2014-06-11|         94.129997|         93.860001|\n",
      "|2014-06-12|         94.040001|         92.290001|\n",
      "|2014-06-13|         92.199997|         91.279999|\n",
      "|2014-06-16|         91.510002|         92.199997|\n",
      "|2014-06-17|         92.309998| 92.08000200000001|\n",
      "|2014-06-18|         92.269997|             92.18|\n",
      "|2014-06-19|         92.290001|         91.860001|\n",
      "|2014-06-20|         91.849998|         90.910004|\n",
      "+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Even though we know SQL is available, let's try out some of the DataFrame methods.\n",
    "# For this example, let's have a look at the opeening and closing value where close is less than 500.\n",
    "df.filter(\"Close < 200\").select('Date','Open','Close').show()\n",
    "df.filter((df[\"Close\"] < 200) & (df[\"Open\"] < 200)).select('Date','Open','Close').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              Open|             Close|\n",
      "+------------------+------------------+\n",
      "|        213.429998|        214.009998|\n",
      "|        214.599998|        214.379993|\n",
      "|        214.379993|        210.969995|\n",
      "|            211.75|            210.58|\n",
      "|        210.299994|211.98000499999998|\n",
      "|212.79999700000002|210.11000299999998|\n",
      "|209.18999499999998|        207.720001|\n",
      "|        207.870005|        210.650002|\n",
      "|210.11000299999998|            209.43|\n",
      "|210.92999500000002|            205.93|\n",
      "|        208.330002|        215.039995|\n",
      "|        214.910006|            211.73|\n",
      "|        212.079994|        208.069996|\n",
      "|206.78000600000001|            197.75|\n",
      "|202.51000200000001|        203.070002|\n",
      "|205.95000100000001|        205.940001|\n",
      "|        206.849995|        207.880005|\n",
      "|        204.930004|        199.289995|\n",
      "|        201.079996|        192.060003|\n",
      "|192.36999699999998|        194.729998|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------------+-----------------+\n",
      "|             Open|            Close|\n",
      "+-----------------+-----------------+\n",
      "|        92.699997|        93.699997|\n",
      "|        94.730003|            94.25|\n",
      "|        94.129997|        93.860001|\n",
      "|        94.040001|        92.290001|\n",
      "|        92.199997|        91.279999|\n",
      "|        91.510002|        92.199997|\n",
      "|        92.309998|92.08000200000001|\n",
      "|        92.269997|            92.18|\n",
      "|        92.290001|        91.860001|\n",
      "|        91.849998|        90.910004|\n",
      "|            91.32|90.83000200000001|\n",
      "|            90.75|        90.279999|\n",
      "|        90.209999|        90.360001|\n",
      "|        90.370003|        90.900002|\n",
      "|            90.82|        91.980003|\n",
      "|        92.099998|            92.93|\n",
      "|        93.519997|        93.519997|\n",
      "|        93.870003|        93.480003|\n",
      "|93.66999799999999|        94.029999|\n",
      "|        94.139999|        95.970001|\n",
      "+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also use Python within the DataFrame filter method!\n",
    "df.filter(df['Close'] < 500).select('Open','Close').show()\n",
    "df.filter((df['Close'] < 100) & (df['Open'] < 100)).select('Open','Close').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              Open|             Close|\n",
      "+------------------+------------------+\n",
      "|        491.500008|502.20999900000004|\n",
      "|494.63999900000005|506.08998099999997|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And we can use multiple operations! \n",
    "# Here we're looking for significant increases in stock.\n",
    "df.filter( (df['Close'] > 500) & (df['Open'] < 495) ).select('Open','Close').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Collect\n",
    "You may have noticed that showing a DataFrame can be quite messy and useless. Instead, let's try using the collect method to visualise the data. It's not necessarily better, just a different method of achieving similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a row of data with a low of $197.16 and collect it.  \n",
    "employeeResult = df.filter(df['Low'] == 197.16).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2010-01-22', Open=206.78000600000001, High=207.499996, Low=197.16, Close=197.75, Volume=220441900, Adj Close=25.620401)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we collect it, you may notice an interesting format. \n",
    "employeeResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date='2010-01-22', Open=206.78000600000001, High=207.499996, Low=197.16, Close=197.75, Volume=220441900, Adj Close=25.620401)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can select the first row of data to shed the outer brackets.\n",
    "employeeRow = employeeResult[0] #employeeResult[0] accesses the first row\n",
    "#employeeRow = employeeResult[0][1] #employeeResult[0][1] accesses the 2nd column of that row\n",
    "employeeRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': '2010-01-22',\n",
       " 'Open': 206.78000600000001,\n",
       " 'High': 207.499996,\n",
       " 'Low': 197.16,\n",
       " 'Close': 197.75,\n",
       " 'Volume': 220441900,\n",
       " 'Adj Close': 25.620401}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then visualise it simply as a dictionary. \n",
    "employeeRow.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-01-22'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why convert it into a dictionary? Because dictionaries have a lot of methods available.\n",
    "# For example, we can simply call volume from the dictionary. \n",
    "employeeRow.asDict()['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation and Dates\n",
    "Let's shift gears a bit and focus on something different. Instead of simply eploring the data, let's try to find the average stock closing price per year. To do this, we'll first have to manipulate the Date column. Let's begin! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the relevant functions.\n",
    "from pyspark.sql.functions import dayofmonth,month,hour,year,format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|Year|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|2010|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|2010|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|2010|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|2010|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|2010|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|2010|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|2010|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|2010|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|2010|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|2010|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|2010|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|2010|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|2010|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|2010|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|2010|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|2010|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|2010|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|2010|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|2010|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|2010|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+-----+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|Month|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+-----+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|    1|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|    1|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|    1|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|    1|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|    1|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|    1|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|    1|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|    1|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|    1|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|    1|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|    1|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|    1|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|    1|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|    1|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|    1|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|    1|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|    1|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|    1|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|    1|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|    2|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And create a new column using the year function to manipulate date. \n",
    "df_with_year = df.withColumn(\"Year\",year(df[\"Date\"]))\n",
    "df.show()\n",
    "df_with_year.show()\n",
    "\n",
    "df_with_month = df.withColumn(\"Month\",month(df[\"Date\"]))\n",
    "df_with_date.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+----+-----+-----+\n",
      "|      Date|              Open|             Close|Year|Month|Dates|\n",
      "+----------+------------------+------------------+----+-----+-----+\n",
      "|2010-01-04|        213.429998|        214.009998|2010|    1|    4|\n",
      "|2010-01-05|        214.599998|        214.379993|2010|    1|    5|\n",
      "|2010-01-06|        214.379993|        210.969995|2010|    1|    6|\n",
      "|2010-01-07|            211.75|            210.58|2010|    1|    7|\n",
      "|2010-01-08|        210.299994|211.98000499999998|2010|    1|    8|\n",
      "|2010-01-11|212.79999700000002|210.11000299999998|2010|    1|   11|\n",
      "|2010-01-12|209.18999499999998|        207.720001|2010|    1|   12|\n",
      "|2010-01-13|        207.870005|        210.650002|2010|    1|   13|\n",
      "|2010-01-14|210.11000299999998|            209.43|2010|    1|   14|\n",
      "|2010-01-15|210.92999500000002|            205.93|2010|    1|   15|\n",
      "|2010-01-19|        208.330002|        215.039995|2010|    1|   19|\n",
      "|2010-01-20|        214.910006|            211.73|2010|    1|   20|\n",
      "|2010-01-21|        212.079994|        208.069996|2010|    1|   21|\n",
      "|2010-01-22|206.78000600000001|            197.75|2010|    1|   22|\n",
      "|2010-01-25|202.51000200000001|        203.070002|2010|    1|   25|\n",
      "|2010-01-26|205.95000100000001|        205.940001|2010|    1|   26|\n",
      "|2010-01-27|        206.849995|        207.880005|2010|    1|   27|\n",
      "|2010-01-28|        204.930004|        199.289995|2010|    1|   28|\n",
      "|2010-01-29|        201.079996|        192.060003|2010|    1|   29|\n",
      "|2010-02-01|192.36999699999998|        194.729998|2010|    2|    1|\n",
      "+----------+------------------+------------------+----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, date_format\n",
    "df_with_ymd = df.withColumn(\"Year\", year(df[\"Date\"])) \\\n",
    "                .withColumn(\"Month\", month(df[\"Date\"])) \\\n",
    "                .withColumn(\"Dates\", dayofmonth(df[\"Date\"]))\n",
    "df_with_ymd.select('Date','Open','Close', 'Year', 'Month', 'Dates').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|         avg(Open)|\n",
      "+----+------------------+\n",
      "|2015|120.17575393253965|\n",
      "|2013| 473.1281355634922|\n",
      "|2014| 295.1426195357143|\n",
      "|2012|     576.652720788|\n",
      "|2016|104.50777772619044|\n",
      "|2010| 259.9576190992064|\n",
      "|2011|364.06142773412705|\n",
      "+----+------------------+\n",
      "\n",
      "+----+------------------+\n",
      "|Year|         avg(Open)|\n",
      "+----+------------------+\n",
      "|2010| 259.9576190992064|\n",
      "|2011|364.06142773412705|\n",
      "|2012|     576.652720788|\n",
      "|2013| 473.1281355634922|\n",
      "|2014| 295.1426195357143|\n",
      "|2015|120.17575393253965|\n",
      "|2016|104.50777772619044|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's sumamrise the data by year, find the mean of each year and select the two columns we'd like to see.\n",
    "df_summary_Year = df_with_year.groupBy(\"Year\").mean().select(['Year','avg(Open)'])\n",
    "df_summary_Year.show()\n",
    "df_summary_Year.orderBy('Year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Month|         avg(Open)|\n",
      "+-----+------------------+\n",
      "|   12|302.76953076510085|\n",
      "|    1|322.90628572142856|\n",
      "|    6|288.75166685333335|\n",
      "|    3| 332.8893468300655|\n",
      "|    5|351.59870752380965|\n",
      "|    9| 301.3590970763887|\n",
      "|    4| 341.0048631506845|\n",
      "|    8| 300.2057422967742|\n",
      "|    7| 281.2487831148649|\n",
      "|   10| 308.5571721973687|\n",
      "|   11|  306.612237797203|\n",
      "|    2| 320.7831106888889|\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|Month|         avg(Open)|\n",
      "+-----+------------------+\n",
      "|    1|322.90628572142856|\n",
      "|    2| 320.7831106888889|\n",
      "|    3| 332.8893468300655|\n",
      "|    4| 341.0048631506845|\n",
      "|    5|351.59870752380965|\n",
      "|    6|288.75166685333335|\n",
      "|    7| 281.2487831148649|\n",
      "|    8| 300.2057422967742|\n",
      "|    9| 301.3590970763887|\n",
      "|   10| 308.5571721973687|\n",
      "|   11|  306.612237797203|\n",
      "|   12|302.76953076510085|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's sumamrise the data by Month, find the mean of each Month and select the two columns we'd like to see.\n",
    "df_summary_Month = df_with_ymd.groupBy(\"Month\").mean().select(['Month','avg(Open)'])\n",
    "df_summary_Month.show()\n",
    "df_summary_Month.orderBy('Month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Dates|         avg(Open)|\n",
      "+-----+------------------+\n",
      "|   31|   335.03625115625|\n",
      "|   28| 316.2089659482759|\n",
      "|   26| 314.0460731428571|\n",
      "|   27| 328.8184208245614|\n",
      "|   12|310.47483123333336|\n",
      "|   22| 297.0716955423729|\n",
      "|    1|301.86599863636366|\n",
      "|   13| 321.4972878305083|\n",
      "|    6|325.53614014035094|\n",
      "|   16| 305.5162059827586|\n",
      "|    3| 324.9258940892858|\n",
      "|   20| 318.2015779473684|\n",
      "|    5|323.07684407017535|\n",
      "|   19| 315.9981353898305|\n",
      "|   15|  305.063053101695|\n",
      "|    9| 305.1209995666666|\n",
      "|   17|308.29421015789484|\n",
      "|    4| 317.8955350357143|\n",
      "|    8| 297.7521300983607|\n",
      "|   23|        308.176668|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+------------------+\n",
      "|Dates|         avg(Open)|\n",
      "+-----+------------------+\n",
      "|    1|301.86599863636366|\n",
      "|    2| 310.9580718070175|\n",
      "|    3| 324.9258940892858|\n",
      "|    4| 317.8955350357143|\n",
      "|    5|323.07684407017535|\n",
      "|    6|325.53614014035094|\n",
      "|    7| 321.1116946949151|\n",
      "|    8| 297.7521300983607|\n",
      "|    9| 305.1209995666666|\n",
      "|   10| 314.1318637966101|\n",
      "|   11|307.28868857377057|\n",
      "|   12|310.47483123333336|\n",
      "|   13| 321.4972878305083|\n",
      "|   14|319.82700136666665|\n",
      "|   15|  305.063053101695|\n",
      "|   16| 305.5162059827586|\n",
      "|   17|308.29421015789484|\n",
      "|   18| 305.5775437894737|\n",
      "|   19| 315.9981353898305|\n",
      "|   20| 318.2015779473684|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's sumamrise the data by Dates, find the mean of each Date and select the two columns we'd like to see.\n",
    "df_summary_Date = df_with_ymd.groupBy(\"Dates\").mean().select(['Dates','avg(Open)'])\n",
    "df_summary_Date.show()\n",
    "df_summary_Date.orderBy('Dates').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the data may be accurate, it's not necessarily appropriate in a professional context. Instead, let's make a few adjustments to make it more appealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+\n",
      "|Year|format_number(avg(Open), 2)|\n",
      "+----+---------------------------+\n",
      "|2015|                     120.18|\n",
      "|2013|                     473.13|\n",
      "|2014|                     295.14|\n",
      "|2012|                     576.65|\n",
      "|2016|                     104.51|\n",
      "|2010|                     259.96|\n",
      "|2011|                     364.06|\n",
      "+----+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To make it more visually appealing, let's format the mean to two decimal places.\n",
    "df_formatted = df_summary_Year.select(['Year', format_number(\"avg(Open)\",2)])\n",
    "df_formatted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+\n",
      "|Year|Average Opening Price|\n",
      "+----+---------------------+\n",
      "|2015|               120.18|\n",
      "|2013|               473.13|\n",
      "|2014|               295.14|\n",
      "|2012|               576.65|\n",
      "|2016|               104.51|\n",
      "|2010|               259.96|\n",
      "|2011|               364.06|\n",
      "+----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's change the name of the column to something that makes sense.\n",
    "df_renamed = df_formatted.withColumnRenamed(\"format_number(avg(Open), 2)\",\"Average Opening Price\")\n",
    "df_renamed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+\n",
      "|Year|Average Opening Price|\n",
      "+----+---------------------+\n",
      "|2010|               259.96|\n",
      "|2011|               364.06|\n",
      "|2012|               576.65|\n",
      "|2013|               473.13|\n",
      "|2014|               295.14|\n",
      "|2015|               120.18|\n",
      "|2016|               104.51|\n",
      "+----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And finally order it by year.\n",
    "df_renamed.orderBy('Year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! At this stage, it's a good idea to continue exploring the basics of DataFrames. Try different methods or reading the documentation.\n",
    "\n",
    "When you feel comfortable, move on to the DataFrame Data Cleaning Exercise. \n",
    "\n",
    "If you would like a simpler aggregation example, try the DataFrame Aggregation Exercise. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
